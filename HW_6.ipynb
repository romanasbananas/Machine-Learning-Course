{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71833815",
   "metadata": {},
   "source": [
    "### Замерим качество Линейной регрессии после обработки данных не просто на отложенной выборке, но и на Кросс-Валидации на 4 фолдах!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4355dcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "processed_data = pd.read_csv('processed_data.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "eb298541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>distance_km</th>\n",
       "      <th>log_trip_duration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id2875421</th>\n",
       "      <td>1</td>\n",
       "      <td>930.399753</td>\n",
       "      <td>0</td>\n",
       "      <td>1.500479</td>\n",
       "      <td>6.122493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id2377394</th>\n",
       "      <td>0</td>\n",
       "      <td>930.399753</td>\n",
       "      <td>0</td>\n",
       "      <td>1.807119</td>\n",
       "      <td>6.498282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id3858529</th>\n",
       "      <td>1</td>\n",
       "      <td>930.399753</td>\n",
       "      <td>0</td>\n",
       "      <td>6.392080</td>\n",
       "      <td>7.661527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id3504673</th>\n",
       "      <td>1</td>\n",
       "      <td>930.399753</td>\n",
       "      <td>0</td>\n",
       "      <td>1.487155</td>\n",
       "      <td>6.063785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id2181028</th>\n",
       "      <td>1</td>\n",
       "      <td>930.399753</td>\n",
       "      <td>0</td>\n",
       "      <td>1.189925</td>\n",
       "      <td>6.077642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           vendor_id  passenger_count  store_and_fwd_flag  distance_km  \\\n",
       "id                                                                       \n",
       "id2875421          1       930.399753                   0     1.500479   \n",
       "id2377394          0       930.399753                   0     1.807119   \n",
       "id3858529          1       930.399753                   0     6.392080   \n",
       "id3504673          1       930.399753                   0     1.487155   \n",
       "id2181028          1       930.399753                   0     1.189925   \n",
       "\n",
       "           log_trip_duration  \n",
       "id                            \n",
       "id2875421           6.122493  \n",
       "id2377394           6.498282  \n",
       "id3858529           7.661527  \n",
       "id3504673           6.063785  \n",
       "id2181028           6.077642  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5debb58c",
   "metadata": {},
   "source": [
    "#### ! Не перемешивайте данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b8678af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.426\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "import numpy as np\n",
    "\n",
    "selector = KFold(n_splits=4)\n",
    "\n",
    "losses = []\n",
    "\n",
    "for train_index, test_index in selector.split(processed_data):\n",
    "    X_train, X_test = processed_data.iloc[train_index][['vendor_id', 'passenger_count', 'store_and_fwd_flag', 'distance_km']], processed_data.iloc[test_index][['vendor_id', 'passenger_count', 'store_and_fwd_flag', 'distance_km']]\n",
    "    y_train, y_test = processed_data.iloc[train_index]['log_trip_duration'], processed_data.iloc[test_index]['log_trip_duration']\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    squared_log_errors = (predictions - y_test) ** 2\n",
    "    msle = np.mean(squared_log_errors)\n",
    "    losses.append(msle)\n",
    "\n",
    "mean_cv_loss = np.mean(losses)\n",
    "\n",
    "print(f\"{round(mean_cv_loss, 3)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a586759d",
   "metadata": {},
   "source": [
    "## Поработал один из хитрых гномов!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9a763e",
   "metadata": {},
   "source": [
    "В отличие от своих собратьев, третий гном оказался тем еще бездельником в школьные годы, но все равно страстно желал во всем догнать первых двух. И сейчас, желая помочь им в построении модели по предсказанию длительности поездки такси, добавил в данные 20 зашифрованных фичей (их смысл нам не рассказали: какая-то секретная информация о водителях).\n",
    "\n",
    "Гном думал следующим образом: \"Ну не может же модель стать хуже! А тут вот авось и мое нововведение уменьшит ошибку в разы! Тогда и меня станут звать на гномий  data-саммит.\"\n",
    "\n",
    "Проверим на кросс-валидации, насколько гном оказался прав!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "538a0adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.read_csv('new_data.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53c5dd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['vendor_id', 'passenger_count', 'store_and_fwd_flag', 'distance_km',\n",
      "       'log_trip_duration', 'feature_1', 'feature_2', 'feature_3', 'feature_4',\n",
      "       'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9',\n",
      "       'feature_10', 'feature_11', 'feature_12', 'feature_13', 'feature_14',\n",
      "       'feature_15', 'feature_16', 'feature_17', 'feature_18', 'feature_19',\n",
      "       'feature_20'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "new_data.head()\n",
    "columns = new_data.columns\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0ae3eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSLE на Кросс-валидации: 140.923\n"
     ]
    }
   ],
   "source": [
    "### Шаг №6\n",
    "### Замерьте качество (MSLE, как и раньше) на Кросс-валидации, \n",
    "### используя MSE от log_trip_duration и назначенный ранее selector\n",
    "\n",
    "### Your code is here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "losses = []\n",
    "splitter = KFold(n_splits=4)\n",
    "\n",
    "for train_index, test_index in splitter.split(new_data):\n",
    "    x_train, x_test = new_data.iloc[train_index][['feature_1', 'feature_2', 'feature_3', 'feature_4',\n",
    "       'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9',\n",
    "       'feature_10', 'feature_11', 'feature_12', 'feature_13', 'feature_14',\n",
    "       'feature_15', 'feature_16', 'feature_17', 'feature_18', 'feature_19',\n",
    "       'feature_20']], new_data.iloc[test_index][['feature_1', 'feature_2', 'feature_3', 'feature_4',\n",
    "       'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9',\n",
    "       'feature_10', 'feature_11', 'feature_12', 'feature_13', 'feature_14',\n",
    "       'feature_15', 'feature_16', 'feature_17', 'feature_18', 'feature_19',\n",
    "       'feature_20']]\n",
    "    y_train,y_test = new_data.iloc[train_index]['log_trip_duration'],new_data.iloc[test_index]['log_trip_duration']\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(x_train,y_train)\n",
    "\n",
    "    predictions = model.predict(x_test)\n",
    "    squared_log_errors = (predictions - y_test) ** 2\n",
    "    msle = np.mean(squared_log_errors)\n",
    "    losses.append(msle)\n",
    "\n",
    "cross_val_error_2 = np.mean(losses)\n",
    "\n",
    "\n",
    "print(f\"MSLE на Кросс-валидации: {round(cross_val_error_2, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8f2945",
   "metadata": {},
   "source": [
    "В линейной алгербре зачастую используют понятие **ранга матрицы**. Оно соответствует кол-ву линейно независимых столбцов в матрице. Иными словами, позволяет оценить, есть ли избыток информации в нашем датафрейме. Если ранг матрицы меньше, чем кол-во используемых столбцов, то некоторые фичи следует удалить, ведь иначе возникает ситуация строгой мультиколлинеарности.\n",
    "\n",
    "Чтобы замерить ранг в наших матрицах объект-признак, можно воспользоваться функцией numpy.linalg.matrix_rank\n",
    "\n",
    "Константным признаком в данном упражнении можно пренебречь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "edcd430c-95b8-474a-a2b7-3d05dadb3385",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = processed_data.drop(['log_trip_duration'], axis=1)\n",
    "new_data = new_data.drop(['log_trip_duration'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cdc8e99b-7f6c-4f38-b12d-16c2444c3378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['vendor_id', 'passenger_count', 'store_and_fwd_flag', 'distance_km'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "columns = processed_data.columns\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e3de617d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Создайте переменные rank_processed, rank_new \n",
    "### Соответственно равные рангу изначальной матрицы\n",
    "### с данными и рангу матрицы третьего гнома\n",
    "\n",
    "### Your code is here\n",
    "rank_processed = np.linalg.matrix_rank(processed_data)\n",
    "rank_new = np.linalg.matrix_rank(new_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "687d03a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Создайте переменные num_features_processed, num_features_new\n",
    "### Соответственно равные кол-ву фичей в изначальной матрицы\n",
    "### с данными и кол-ву фичей у третьего гнома\n",
    "\n",
    "### Your code is here\n",
    "num_features_processed = processed_data.shape[1]\n",
    "num_features_new = new_data.shape[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2820bee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В первой модели всего фичей: 4, - а ранг равен 4\n",
      "Во второй модели всего фичей: 24, - а ранг равен 5\n"
     ]
    }
   ],
   "source": [
    "### Шаг №7\n",
    "print(f\"В первой модели всего фичей: {num_features_processed}, - а ранг равен {rank_processed}\")\n",
    "\n",
    "print(f\"Во второй модели всего фичей: {num_features_new}, - а ранг равен {rank_new}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a194b8ab",
   "metadata": {},
   "source": [
    "Не кажется ли нам, что из-за новых 20 фичей появилась проблема мультиколлинеарности? Как поступить гному, чтобы, с одной стороны, получить адекватное качество, а с другой стороны, не повредить свое самолюбие и не убирать новые признаки?\n",
    "\n",
    "Верно! Например, с помощью регуляризации.\n",
    "\n",
    "Найдите такой параметр регуляризации $\\alpha$ для Ridge и Lasso случая, чтобы ошибка MSLE на кросс-валидации оказалась строго меньше 0.4\n",
    "\n",
    "**ALARM**: используйте процедуру масштабирования данных (воспользуйтесь методом MinMaxScaler) перед тем как применить регуляризацию. Важно - чтобы сохранить концепцию независимости обучения на трейне и на тесте, на каждой итерации кросс-валидации необходимо замерять параметры стандартизации исключительно на трейне, а потом применять на валидационном фолде."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5e40302d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSLE на Кросс-валидации равен: 0.6332330617999488\n"
     ]
    }
   ],
   "source": [
    "### Пример, как это можно сделать в цикле\n",
    "### То есть обучить Lasso, учитывая масштабирование\n",
    "### Исключительно на трейне на каждой итерации\n",
    "X = new_data.drop('log_trip_duration', axis=1)\n",
    "Y = new_data['log_trip_duration']\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "scores = []\n",
    "\n",
    "for train_index, test_index in selector.split(X):\n",
    "    \n",
    "    X_train, X_test = X.values[train_index], X.values[test_index]\n",
    "    Y_train, Y_test = Y.values[train_index], Y.values[test_index]\n",
    "    \n",
    "    ### Фитим исключительно на трейне!\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    \n",
    "    ### Применяем обученный scaler на трейн и тест\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    ### max_iter иногда требуется ставить побольше, \n",
    "    ### особенно когда данных много и/или они сложные\n",
    "    ### этот параметр регулирует верхнюю границу кол-ва\n",
    "    ### итераций во время обучения\n",
    "    ### подробнее - в документации\n",
    "    \n",
    "    ### По дефолту здесь параметр регуляризации alpha=1\n",
    "    \n",
    "    model_lasso = Lasso(max_iter=100000) \n",
    "    model_lasso.fit(X_train_scaled, Y_train)\n",
    "    \n",
    "    predictions = model_lasso.predict(X_test_scaled)\n",
    "    \n",
    "    scores.append(np.mean((predictions - Y_test)**2))\n",
    "\n",
    "    \n",
    "print(f\"MSLE на Кросс-валидации равен: {np.mean(scores)}\")\n",
    "\n",
    "### P.S. если вы уже умеете работать с конструкциями\n",
    "### Pipeline, GridSearchCV, cross_validate\n",
    "### Можете использовать их. Мы познакомимся с ними позже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "aa4bf132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучший параметр регуляризации для Lasso: 0.00004\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X = new_data.drop('log_trip_duration', axis=1)\n",
    "Y = new_data['log_trip_duration']\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "alphas = np.linspace(1e-5, 1e-4, 10)\n",
    "\n",
    "best_alpha = None\n",
    "best_score = float('inf')\n",
    "\n",
    "for alpha in alphas:\n",
    "    scores = []\n",
    "    for train_index, test_index in selector.split(X):\n",
    "        X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "        Y_train, Y_test = Y.values[train_index], Y.values[test_index]\n",
    "\n",
    "        model_lasso = Lasso(alpha=alpha, max_iter=100000)\n",
    "        model_lasso.fit(X_train, Y_train)\n",
    "\n",
    "        predictions = model_lasso.predict(X_test)\n",
    "\n",
    "        scores.append(mean_squared_error(Y_test, predictions))\n",
    "\n",
    "    mean_score = np.mean(scores)\n",
    "    if mean_score < 0.4 and mean_score < best_score:\n",
    "        best_score = mean_score\n",
    "        best_alpha = alpha\n",
    "\n",
    "print(f\"Лучший параметр регуляризации для Lasso: {best_alpha:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222e6a21-fb5e-43b1-b84a-79d4d3674c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
